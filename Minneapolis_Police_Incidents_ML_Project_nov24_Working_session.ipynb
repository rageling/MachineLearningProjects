{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Minneapolis_Police_Incidents_ML_Project_nov24_Working_session.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDA9sbqbxQgX",
        "colab_type": "text"
      },
      "source": [
        "Project Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX9zl21uxR2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IMPORT FILES FROM DRIVE INTO GOOGLE-COLAB:\n",
        "\n",
        "#STEP-1: Import Libraries\n",
        "\n",
        "# Code to read csv file into colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#STEP-2: Autheticate E-Mail ID\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#STEP-3: Get File from Drive using file-ID\n",
        "\n",
        "#2.1 Get the file\n",
        "downloaded = drive.CreateFile({'id':'1dDC9SZCUCF4VWBcv-zqdwPU5Gn8yqTF7'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('Police_Incidents_2018.csv') \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mjMVMOvZxQgd",
        "colab_type": "code",
        "outputId": "18089033-b578-4149-a4ab-15d3f17e2b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import array\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#load dataset\n",
        "\n",
        "df = pd.read_csv(\"Police_Incidents_2018.csv\")\n",
        "\n",
        "\n",
        "#Create \"Hours\", \"BeginDate\" and \"dayofyear\" parameters\n",
        "df[\"Hours\"] = df.Time.str.split(':').str[0].astype(int)  \n",
        "df['BeginDate'] = pd.to_datetime(df['BeginDate']) \n",
        "df['dayofyear'] = df['BeginDate'].dt.dayofyear \n",
        "\n",
        "\n",
        "#Create labels called \"Night\", \"Morning\", \"Afternoon\", and \"Evening\"\n",
        "df.assign(session=pd.cut(df.Hours,[0,6,12,18,24],labels=['Night','Morning','Afternoon','Evening']))  \n",
        "prods = pd.DataFrame({'Time':range(1, 25)}) \n",
        "b = [0,4,8,12,16,20,24] \n",
        "l = ['Late Night', 'Early Morning','Morning','Noon','Eve','Night'] \n",
        "df['Timeofday'] = pd.cut(df['Hours'], bins=b, labels=l) \n",
        "\n",
        "\n",
        "bins = [0, 91, 183, 275, 366] \n",
        "labels=['Winter', 'Spring', 'Summer', 'Fall'] \n",
        "\n",
        "df['SEASON'] = pd.cut(df['dayofyear'] + 11 - 366*(df['dayofyear'] > 355), bins=bins, labels=labels)\n",
        "\n",
        "\n",
        "#16- Neighborhood\n",
        "#23- Time of Day\n",
        "#22 Season\n",
        "#3-Precinct,\n",
        "#11-GBSID,\n",
        "#12-Lat\n",
        "#13-Long\n",
        "X = df.iloc[:,[16,23,22,3,11,12,13]].values\n",
        "\n",
        "#9-UCR Code our Class Label\n",
        "y = df.iloc[:,9].values\n",
        "\n",
        "# SimpleImputer\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "imputer.fit(X[:,:])\n",
        "X[:,:]=imputer.transform(X[:,:])\n",
        "print(\"SimpleImputer-Complete\")\n",
        "\n",
        "\n",
        "#Neighbourhood in one hot encoding \n",
        "data = X[:,0]\n",
        "values = array(data)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False,categorical_features=[0])\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "#concatenate OHE to the features set X\n",
        "X = np.concatenate((X,onehot_encoder.fit_transform(integer_encoded)),axis=1)\n",
        "#drop the Neighborhood column\n",
        "X = X[:,1:]\n",
        "print(\"one hot encoding on Neighborhood-Complete\")\n",
        "\n",
        "\n",
        "# one hot encoding on TimeOfDay\n",
        "\n",
        "data = X[:,0]\n",
        "values = array(data)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False,categorical_features=[0])\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "#concatenate OHE to the features set X\n",
        "X = np.concatenate((X,onehot_encoder.fit_transform(integer_encoded)),axis=1)\n",
        "#drop the Timeofday column\n",
        "X = X[:,1:]\n",
        "print(\"one hot encoding on Time-Complete\")\n",
        "\n",
        "\n",
        "# one hot encoding on Season #Column index =0 #Neighbourhood in one hot encoding \n",
        "data = X[:,0] \n",
        "values = array(data) # integer encode \n",
        "label_encoder = LabelEncoder() \n",
        "integer_encoded = label_encoder.fit_transform(values) # binary encode \n",
        "onehot_encoder = OneHotEncoder(sparse=False,categorical_features=[0]) \n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1) #concatenate OHE to the features set X \n",
        "X = np.concatenate((X,onehot_encoder.fit_transform(integer_encoded)),axis=1) #drop the Season column \n",
        "X = X[:,1:] \n",
        "print(\"one hot encoding on Season\") \n",
        "\n",
        "\n",
        "# Splitting \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y, test_size=0.3)\n",
        "\n",
        "\n",
        "# Normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.fit_transform(X_test)\n",
        "\n",
        "\n",
        "#Applying PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pcaObj = PCA(n_components=4)\n",
        "X_train = pcaObj.fit_transform(X_train)\n",
        "X_test = pcaObj.transform(X_test)\n",
        "components_variance = pcaObj.explained_variance_ratio_\n",
        "\n",
        "print(components_variance)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SimpleImputer-Complete\n",
            "one hot encoding on Neighborhood-Complete\n",
            "one hot encoding on Time-Complete\n",
            "one hot encoding on Season\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.02301507 0.02004342 0.01441111 0.01313143]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQyI4RhyxQg9",
        "colab_type": "code",
        "outputId": "bdce7c31-91ae-4d80-a7aa-d693b4c88b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#this is SVM\n",
        "\n",
        "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj \n",
        "\n",
        "from sklearn.svm import SVC\n",
        "classifierObj = SVC()\n",
        "\n",
        "\n",
        "grid_param = { \n",
        " \n",
        "     'kernel': ['linear'],#'linear', 'poly', 'sigmoid'], \n",
        "      'C': [10],\n",
        "    #'degree': [3,4,5],\n",
        "    'gamma': [1],\n",
        "    #'shrinking': [True, False],\n",
        "    #'probability': [False, True],\n",
        "    #'tol': [0.001],\n",
        "    #'verbose': [False, True],\n",
        "    #'max_iter': [-1],\n",
        "    #'decision_function_shape':['ovr','ovo']\n",
        "    \n",
        "}\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "gd_sr = GridSearchCV(estimator=classifierObj, param_grid=grid_param, scoring='accuracy', cv=5, n_jobs=-1) \n",
        "gd_sr.fit(X_train, y_train) \n",
        "print(\"Fitting SVM\")\n",
        "print(gd_sr.best_params_)  \n",
        "print('The Accuracy Score is:', gd_sr.best_score_)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting SVM\n",
            "{'C': 10, 'gamma': 1, 'kernel': 'linear'}\n",
            "The Accuracy Score is: 0.5628765792031099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ac4f1277-18d1-4a5a-da78-1d80e09a2810",
        "id": "_O_i0GoL6_10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Fitting Naive Bayes\n",
        "# GridSearch cannot be performed on GaussianNaiveBayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "gnb = GaussianNB()\n",
        "print(\"naive bayes start\")\n",
        "\n",
        "GNB_trainedModel = gnb.fit(X_train, y_train)\n",
        "print(\"naive bayes trained!\")\n",
        "gnb_pred = GNB_trainedModel.predict(X_test)\n",
        "GNB_score = metrics.accuracy_score(y_test, gnb_pred)\n",
        "print(\"naive bayes predicted!\")\n",
        "print(\"complete\")\n",
        "print('The Accuracy score is:', GNB_score)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "naive bayes start\n",
            "naive bayes trained!\n",
            "naive bayes predicted!\n",
            "complete\n",
            "The Accuracy score is: 0.5569160997732426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSq2hHrYxQhH",
        "colab_type": "code",
        "outputId": "f2d96dfd-5573-4a4b-c9bf-99a80ef985f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "#Fitting decision tree\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifierObj = DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "grid_param = { \n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'min_samples_split': [2,3],\n",
        "    'min_samples_leaf': [1,2],\n",
        "    'min_weight_fraction_leaf': [0],\n",
        "    'max_features': ['auto'],\n",
        "    'min_impurity_decrease': [0],\n",
        "    #'min_impurity_split': [1e-7],deprecated \n",
        "    'class_weight': ['balanced'],\n",
        "    'presort':[False]\n",
        "}\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "gd_sr = GridSearchCV(estimator=classifierObj, param_grid=grid_param, scoring='accuracy', cv=5, n_jobs=-1) \n",
        "gd_sr.fit(X_train, y_train) \n",
        "print(\"Fitting decision tree\")\n",
        "print(gd_sr.best_params_)  \n",
        "print('The Accuracy Score is:', gd_sr.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting decision tree\n",
            "{'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'auto', 'min_impurity_decrease': 0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0, 'presort': False}\n",
            "The Accuracy Score is: 0.40641399416909624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bmxl720xQhL",
        "colab_type": "code",
        "outputId": "8c31239a-caee-498c-a4f6-ab7ec114f559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifierObj = RandomForestClassifier()\n",
        "\n",
        "\n",
        "grid_param = { \n",
        "    'n_estimators': [300]\n",
        "   #  'criterion': ['gini'],\n",
        "#     'max_depth': ['None'],\n",
        "#     'min_samples_split': [2],\n",
        "#     'min_samples_leaf': [1],\n",
        "#     'min_weight_fraction_leaf': [0],\n",
        "#     'max_features': ['auto'],\n",
        "#     'max_leaf_nodes': ['None'],\n",
        "#     'min_impurity_decrease': [0],\n",
        "#     'min_impurity_split': [1e-7],\n",
        "#     'bootstrap':[True],\n",
        "#     'oob_score': [False],\n",
        "#     'n_jobs':['None'],\n",
        "#     #'random_state': ['None'],\n",
        "#     'verbose':[0],\n",
        "#     'warm_start': [False]\n",
        "#     #'class_weight': ['None']\n",
        "}\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "gd_sr = GridSearchCV(estimator=classifierObj, param_grid=grid_param, scoring='accuracy', cv=6, n_jobs=-1) \n",
        "gd_sr.fit(X_train, y_train) \n",
        "\n",
        "print(gd_sr.best_params_)  \n",
        "print('The Accuracy Score is:', gd_sr.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=6.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': 300}\n",
            "The Accuracy Score is: 0.49523809523809526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KIgoCcCxQhZ",
        "colab_type": "code",
        "outputId": "4fbe7379-a457-46e1-a907-d159b76a0d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "# ---------- KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "grid_param = {\n",
        "    'n_neighbors':[43],\n",
        "    'weights':['uniform', 'distance'],\n",
        "    'metric': ['euclidean','manhattan','minkowski']\n",
        "\n",
        "}\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "gd_sr = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=grid_param, scoring='accuracy', cv=5, n_jobs=-1) \n",
        "gd_sr.fit(X_train, y_train) \n",
        "print(\"Fitting KNN\")\n",
        "print(gd_sr.best_params_)  \n",
        "print(gd_sr.best_score_)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting KNN\n",
            "{'metric': 'manhattan', 'n_neighbors': 43, 'weights': 'uniform'}\n",
            "0.5615160349854227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as6AFSVf4O7k",
        "colab_type": "code",
        "outputId": "9f08c10e-ee35-4781-d6fe-5125a1b754ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#2 classifierObjKNN_168 with 168 neighbors for K-NN\n",
        "classifierObjKNN = KNeighborsClassifier(n_neighbors=43, p=2, metric='manhattan')\n",
        "\n",
        "#3 classifierObjSVC_lr with a linear kernel for SVM\n",
        "classifierObjSVC = SVC(kernel = 'linear')\n",
        "\n",
        "#4 classifierObjNB for Naive Bayes\n",
        "classifierObjGNB = GaussianNB()\n",
        "#5 classifierObjRF_57 with 57 estimators for random forest\n",
        "classifierObjRF = RandomForestClassifier(n_estimators=57, criterion='entropy')\n",
        "\n",
        "classifierObjVC = VotingClassifier(estimators=[('kNN', classifierObjKNN),\n",
        "                                               ('SVM', classifierObjSVC),\n",
        "                                               ('NB', classifierObjGNB),\n",
        "                                               ('RF', classifierObjRF)], voting='hard')\n",
        "# fit the model\n",
        "classifierObjVC.fit(X_train,y_train)\n",
        "\n",
        "#Making predictions on the Test Set\n",
        "y_pred_VC = classifierObjVC.predict(X_test)\n",
        "\n",
        "#Test Error \n",
        "Test_Error = 1 - metrics.accuracy_score(y_test, y_pred_VC)\n",
        "\n",
        "print('Accuracy using kNN is:' , cross_val_score(classifierObjKNN,X_train,y_train,scoring='accuracy',cv=6).mean())\n",
        "print('Accuracy using SVC is:' , cross_val_score(classifierObjSVC,X_train,y_train,scoring='accuracy',cv=6).mean())\n",
        "print('Accuracy using GNB is:' , cross_val_score(classifierObjGNB,X_train,y_train,scoring='accuracy',cv=6).mean())\n",
        "print('Accuracy using Random Forest is:' , cross_val_score(classifierObjRF,X_train,y_train,scoring='accuracy',cv=6).mean())\n",
        "\n",
        "print('The Accuracy Score from Ensemble is :', metrics.accuracy_score(y_test, y_pred_VC))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=6.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy using kNN is: 0.5587936155160306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=6.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy using SVC is: 0.5628792400317572\n",
            "Accuracy using GNB is: 0.55472202524493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=6.\n",
            "  % (min_groups, self.n_splits)), Warning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 5 members, which is too few. The minimum number of members in any class cannot be less than n_splits=6.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Random Forest is: 0.4925341733375925\n",
            "The Accuracy Score from Ensemble is : 0.5578231292517006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMgPMCgn15VC",
        "colab_type": "code",
        "outputId": "ae86e434-45fc-4744-f5ea-35f91943fca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Creating a pipeline \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from sklearn.decomposition import PCA \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.pipeline import make_pipeline \n",
        "pipe_lr = make_pipeline(StandardScaler(), PCA(n_components=2), KNeighborsClassifier(n_neighbors=43, p=2, metric='minkowski'))  \n",
        "pipe_lr.fit(X_train, y_train) \n",
        "y_pred = pipe_lr.predict(X_test) \n",
        "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.559\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}